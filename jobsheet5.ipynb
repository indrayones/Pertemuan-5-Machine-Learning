{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  35.0      Chicago\n",
      "3    Alice  25.0     New York\n",
      "4      Eve   NaN        Miami\n",
      "5      NaN  50.0  Los Angeles\n",
      "\n",
      "Data Setelah Cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>32.5</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name   Age         City\n",
       "0    Alice  25.0     New York\n",
       "1      Bob  30.0  Los Angeles\n",
       "2  Charlie  35.0      Chicago\n",
       "4      Eve  32.5        Miami"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contoh Data Cleaning dengan Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Membuat dataframe contoh\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menampilkan data awal\n",
    "print(\"Data Awal:\")\n",
    "print(df)\n",
    "\n",
    "# Menghapus duplikat\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Menangani missing values dengan mengisi nilai median untuk kolom numerik\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Menghapus baris yang mengandung missing values di kolom 'Name'\n",
    "df = df.dropna(subset=['Name'])\n",
    "\n",
    "# Menampilkan data setelah cleaning\n",
    "print(\"\\nData Setelah Cleaning:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "Name          0\n",
      "Age           0\n",
      "City          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifikasi Missing Values\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  35.0      Chicago\n",
      "3    Alice  25.0     New York\n",
      "4      Eve   NaN        Miami\n",
      "5      NaN  50.0  Los Angeles\n",
      "\n",
      "Data Setelah Cleaning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\140385493.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)  # Median\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\140385493.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mode()[0], inplace=True)  # Mode\n"
     ]
    }
   ],
   "source": [
    "# Contoh Data Cleaning dengan Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Membuat dataframe contoh\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menampilkan data awal\n",
    "print(\"Data Awal:\")\n",
    "print(df)\n",
    "\n",
    "# Menghapus duplikat\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Menangani missing values dengan mengisi nilai median untuk kolom numerik\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Menghapus baris yang mengandung missing values di kolom 'Name'\n",
    "df = df.dropna(subset=['Name'])\n",
    "\n",
    "# Menampilkan data setelah cleaning\n",
    "print(\"\\nData Setelah Cleaning:\")\n",
    "df\n",
    "\n",
    "# Mengisi Missing Values\n",
    "df['Age'].fillna(df['Age'].mean())  # Mean\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)  # Median\n",
    "df['Age'].fillna(df['Age'].mode()[0], inplace=True)  # Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  35.0      Chicago\n",
      "3    Alice  25.0     New York\n",
      "4      Eve   NaN        Miami\n",
      "5      NaN  50.0  Los Angeles\n",
      "\n",
      "Data Setelah Cleaning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\669973466.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\669973466.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\669973466.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(method='bfill', inplace=True)  # Backward fill\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\669973466.py:32: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Age'].fillna(method='bfill', inplace=True)  # Backward fill\n"
     ]
    }
   ],
   "source": [
    "# Contoh Data Cleaning dengan Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Membuat dataframe contoh\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menampilkan data awal\n",
    "print(\"Data Awal:\")\n",
    "print(df)\n",
    "\n",
    "# Menghapus duplikat\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Menangani missing values dengan mengisi nilai median untuk kolom numerik\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Menghapus baris yang mengandung missing values di kolom 'Name'\n",
    "df = df.dropna(subset=['Name'])\n",
    "\n",
    "# Menampilkan data setelah cleaning\n",
    "print(\"\\nData Setelah Cleaning:\")\n",
    "df\n",
    "\n",
    "# Forward/Backward Fill\n",
    "df['Age'].fillna(method='ffill', inplace=True)  # Forward fill\n",
    "df['Age'].fillna(method='bfill', inplace=True)  # Backward fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "      Name   Age         City\n",
      "0    Alice  25.0     New York\n",
      "1      Bob  30.0  Los Angeles\n",
      "2  Charlie  35.0      Chicago\n",
      "3    Alice  25.0     New York\n",
      "4      Eve   NaN        Miami\n",
      "5      NaN  50.0  Los Angeles\n",
      "\n",
      "Data Setelah Cleaning:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['column']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9192\\421648709.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nData Setelah Cleaning:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Dropping Missing Values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'column'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['column']"
     ]
    }
   ],
   "source": [
    "# Contoh Data Cleaning dengan Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Membuat dataframe contoh\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menampilkan data awal\n",
    "print(\"Data Awal:\")\n",
    "print(df)\n",
    "\n",
    "# Menghapus duplikat\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Menangani missing values dengan mengisi nilai median untuk kolom numerik\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Menghapus baris yang mengandung missing values di kolom 'Name'\n",
    "df = df.dropna(subset=['Name'])\n",
    "\n",
    "# Menampilkan data setelah cleaning\n",
    "print(\"\\nData Setelah Cleaning:\")\n",
    "df\n",
    "\n",
    "# Dropping Missing Values\n",
    "df.dropna(subset=['column'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Identifikasi duplikat\n",
    "print(df.duplicated().sum())\n",
    "\n",
    "# Menghapus duplikat\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      " Empty DataFrame\n",
      "Columns: [Name, Age, City]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\4220109551.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "C:\\Users\\natha\\AppData\\Local\\Temp\\ipykernel_9192\\4220109551.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Name'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Langkah 1: Membuat DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Langkah 2: Identifikasi Outliers\n",
    "# Outliers dapat diidentifikasi menggunakan berbagai metode, salah satu yang umum adalah menggunakan Z-score atau IQR (Interquartile Range).\n",
    "# Di sini, kita akan menggunakan IQR untuk mendeteksi outliers.\n",
    "# Menghitung IQR\n",
    "Q1 = df['Age'].quantile(0.25)\n",
    "Q3 = df['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Menentukan batas bawah dan atas untuk outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Menandai outliers\n",
    "outliers = df[(df['Age'] < lower_bound) | (df['Age'] > upper_bound)]\n",
    "print(\"Outliers:\\n\", outliers)\n",
    "\n",
    "\n",
    "# Langkah 3: Menangani Outliers\n",
    "# # Menghapus outliers\n",
    "df_no_outliers = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
    "\n",
    "# Mengganti outliers dengan nilai median\n",
    "median_age = df['Age'].median()\n",
    "df['Age'] = np.where((df['Age'] < lower_bound) | (df['Age'] > upper_bound), median_age, df['Age'])\n",
    "\n",
    "# Mengisi missing values dengan median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Name'].fillna('Unknown', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   City_Chicago  City_Los Angeles  City_Miami  City_New York\n",
      "0         False             False       False           True\n",
      "1         False              True       False          False\n",
      "2          True             False       False          False\n",
      "3         False             False       False           True\n",
      "4         False             False        True          False\n"
     ]
    }
   ],
   "source": [
    "# Contoh: misalnya, kita memiliki dataset dengan kolom \"City\" yang berisi data kategorikal:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_one_hot = pd.get_dummies(df, columns=['City'])\n",
    "\n",
    "print(df_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 50],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Menghapus Data Tidak Valid: Jika jumlah data tidak valid kecil dan tidak signifikan, menghapusnya bisa menjadi solusi yang cepat dan mudah.\n",
    "df = df.dropna(subset=['Age', 'Name'])  # Menghapus baris dengan nilai 'Age' atau 'Name' yang tidak valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengganti dengan Nilai Lain:\n",
    "\n",
    "# Mengisi dengan Rata-rata/Median: Mengisi nilai yang hilang atau tidak valid dengan rata-rata atau median.\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Mengisi dengan Nilai Default: Mengisi dengan nilai default yang logis atau sesuai konteks.\n",
    "df['Name'] = df['Name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi Data: Mengubah data tidak valid menjadi format yang sesuai.\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Mengubah nilai 'Age' yang tidak valid menjadi NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembersihan dengan Logika Bisnis: Menggunakan aturan bisnis untuk memperbaiki data. Misalnya, jika usia tidak masuk akal (misalnya lebih dari 120 tahun), maka ubah atau hapus.\n",
    "df = df[(df['Age'] >= 0) & (df['Age'] <= 120)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Awal:\n",
      "      Name    Age         City\n",
      "0    Alice   25.0     New York\n",
      "1      Bob   30.0  Los Angeles\n",
      "2  Charlie   35.0      Chicago\n",
      "3    Alice   25.0     New York\n",
      "4      Eve    NaN        Miami\n",
      "5      NaN  150.0  Los Angeles\n",
      "\n",
      "Data Setelah Menangani Nilai Tidak Valid:\n",
      "      Name    Age         City\n",
      "0    Alice   25.0     New York\n",
      "1      Bob   30.0  Los Angeles\n",
      "2  Charlie   35.0      Chicago\n",
      "3    Alice   25.0     New York\n",
      "4      Eve   30.0        Miami\n",
      "5  Unknown  150.0  Los Angeles\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Eve', np.nan],\n",
    "    'Age': [25, 30, 35, 25, np.nan, 150],  # 150 dianggap sebagai nilai tidak valid\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Miami', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identifikasi nilai tidak valid\n",
    "print(\"Data Awal:\")\n",
    "print(df)\n",
    "\n",
    "# Mengubah nilai 'Age' yang tidak valid menjadi NaN\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "\n",
    "# Mengisi nilai 'Age' yang hilang atau tidak valid dengan median\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Mengisi nilai 'Name' yang hilang dengan 'Unknown'\n",
    "df['Name'] = df['Name'].fillna('Unknown')\n",
    "\n",
    "print(\"\\nData Setelah Menangani Nilai Tidak Valid:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli:\n",
      "   Age  Salary\n",
      "0   25   50000\n",
      "1   30   60000\n",
      "2   35   70000\n",
      "3   40   80000\n",
      "4   45   90000\n",
      "\n",
      "Min-Max Scaled Data:\n",
      "    Age  Salary\n",
      "0  0.00    0.00\n",
      "1  0.25    0.25\n",
      "2  0.50    0.50\n",
      "3  0.75    0.75\n",
      "4  1.00    1.00\n",
      "\n",
      "Standardized Data:\n",
      "        Age    Salary\n",
      "0 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107\n",
      "2  0.000000  0.000000\n",
      "3  0.707107  0.707107\n",
      "4  1.414214  1.414214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Contoh dataset\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Min-Max Scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_min_max_scaled = pd.DataFrame(min_max_scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Z-Score Normalization\n",
    "standard_scaler = StandardScaler()\n",
    "df_standard_scaled = pd.DataFrame(standard_scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(\"Data Asli:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nMin-Max Scaled Data:\")\n",
    "print(df_min_max_scaled)\n",
    "\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(df_standard_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation Scores: [nan nan nan nan nan]\n",
      "Mean Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Contoh dataset\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5)\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "print(\"K-Fold Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation Scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
      "Mean Score: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Implementasi K-Fold Cross-Validation di Python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # Misalnya, menggunakan 5 folds dengan shuffle dan seed random 42\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(\"K-Fold Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 13.7\n",
      "95% Confidence Interval: 11.5 - 15.902499999999998\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "data = np.array([10, 15, 8, 12, 14, 20, 18, 16, 11, 13])\n",
    "\n",
    "# Bootstrap sampling\n",
    "n_samples = 1000\n",
    "bootstrap_means = np.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Confidence interval (95%)\n",
    "ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(\"Mean:\", np.mean(data))\n",
    "print(\"95% Confidence Interval:\", ci_lower, \"-\", ci_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Bagi dataset menjadi data pelatihan dan data pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi dan latih model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi dengan data pengujian\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluasi kinerja model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Contoh Confussion Matrix di NLP\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Impor library yang diperlukan\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m movie_reviews\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Contoh Confussion Matrix di NLP\n",
    "# Impor library yang diperlukan\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Unduh dataset sentimen ulasan film dari NLTK\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "# Ambil ulasan dan label dari dataset\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Pisahkan teks ulasan dan label\n",
    "texts = [' '.join(document) for document, category in documents]\n",
    "labels = [category for document, category in documents]\n",
    "\n",
    "# Ubah teks menjadi vektor fitur TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Bagi dataset menjadi data pelatihan dan data pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi dan latih model klasifikasi (misalnya, Linear SVM)\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Prediksi kelas pada data pengujian\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluasi model menggunakan confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Evaluasi model menggunakan classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
